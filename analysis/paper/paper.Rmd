---
title: "How to use replication assignments for teaching integrity in empirical archaeology"
author:
  - Ben Marwick, bmarwick@uw.edu
  - Liying Wang
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---




```{r, setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/"
)
```


```{r setup2, eval = FALSE}
gh repo: https://github.com/benmarwick/replicationteachingarchaeology
# devtools::install_github("ekothe/rmdrive")
library(rmdrive)


# get text from google doc into Rmd
download_rmd(file = "paper",  # do not include the .Rmd 
             gfile = "Paper: Replication projects for teaching integrity in empirical archaeology")  # name of google doc file


# push updates from Rmd to google doc
update_rmd(file = "analysis/paper/paper",    # do not include the .Rmd 
           gfile = "Paper: Replication projects for teaching integrity in empirical archaeology")  # name of google doc file


```


## Introduction


In many research communities there are changes underway that promote or require high levels of transparency and reproducibility of research. For example... using open source programming language such as R or Python...


Archaeologists are increasingly adopting these practices also. For example… However current norms in teaching archaeology are out of step with these practices. Given shifts in community values, it is important that we prepare our students with the skills necessary to fulfill these expectations of greater transparency and reproducibility in research. Here we propose a new type of assignment, the replication report, to better align the practice of teaching archaeology with the ideals of archaeological practise. The replication report assignment involves three key steps: 1) students analysing a published report to determine what are the main claims made by the authors of that report, 2) students obtaining the data used by the authors, and 3) analysing that data to determine if one or more of the authors’ claims are reliable.  


In this paper we describe how to implement a replication report assignment suitable for upper level undergraduates and graduate students in archaeology. Our experience is based on an upper level archaeology class on stone artefact analysis taught during the spring quarter of 2019 at the University of Washington. The class format includes a weekly cycle of lecture, discussion seminar, and hands-on laboratory activities. The assignments include seminar notes, lecture quizzes, laboratory worksheets, and two longer empirical reports. For the term that we report here, the class had 16 students, and one graduate student teaching assistant. THis is a typical size for this class, and similar to the usual size of upper-level laboratory classes in the archaeology program at the University of Washington. The background of our students are mostly in humanities with diverse level of statistical knowledge. Here we survey the literature on similar types of assignments in other fields to identify common elements that other fields have identified as important principles and skills. We describe our assignment and discuss student feedback on our implementation. Finally we offer recommendations for how to use replication reports to teach archaeology students. 


## Background


What does Barba say about the Ddefinitions of ‘replication’ and ‘reproducibility’? https://arxiv.org/abs/1802.03311 ? 


What are the definitions that we use? http://sites.nationalacademies.org/sites/reproducibility-in-science/index.htm 


What other academic fields value replication? How? By their journals and their teaching methods


What journals require replication materials? Answers in https://politicalsciencereplication.wordpress.com/2018/07/14/replication-and-transparency-in-political-science-did-we-make-any-progress/  what materials exactly do they require? What do we know about how successful that is? Answers in https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/how-are-we-doing-data-access-and-replication-in-political-science/8EE49C7FE45B46F20A50D9271BB3AAC4 and https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/lessons-from-a-decade-of-replications-at-the-quarterly-journal-of-political-science/284B2830BFD99888B42D4CEABC28B9EE 


What previous examples of replication assignments in other fields? ~3-6 sentences to summarise who/what/how/etc. of each one.




What are the typical and unusual elements for replication assignments in other fields?


Other courses in our program at UW do not include this kind of assignment, and they are not common in other programs, to the best of our knowledge. We posted to the Society of American Archaeology Teaching Archaeology Interest Group to ask for examples of replication assignments used in teaching archaeology, and received no replies from anyone teaching with replication. However, we did receive some offers from researchers willing to share their data for future replication assignments. We replied that our assignment required students to find public open data linked to publications, and that privately circulated data would not satisfy our requirements. 


## Methods


A brief discussion of our replication report assignment was announced at the beginning of the term to give students background about the purpose and concepts of replication and our expectations. Our replication report assignment consisted of three small, graded activities to scaffold the preparation of the final report. The first step started from week four and each step was separated by one week to give students time to work and submit their final reports due on week seven. Students were expected to work in groups of 3-4 people, but submit their assignments for each of the three steps and the final report individually. Submissions for each step were graded as complete/incomplete, with feedback provided individually via the Canvas learning management system, and collectively during class meetings. Our course had no prerequisites, so we assumed no prior knowledge of R among the students, and were prepared to teach them as complete novices. We were also prepared for students to have no prior experience with replication assignments.


For the first step we supplied students with a list of journal articles that included raw data and R code either in supplemental files or deposited on open data repositories. This list is updated regularly, but is not exhaustive, and is currently online at https://github.com/benmarwick/ctv-archaeology. Working in groups of 3-4 people, students selected a journal article from this list as their target article for this assignment. We encouraged them to choose a target article about a stone artefact analysis that looked interesting to them. We also required students to set up an open communication channel for their group to ensure they had an easy way to discuss their selection of the target article. We used Slack, a free cloud-based web application for team communication, to help them collaborate with each other efficiently. The instructors were members of all the student group channels to supervise, give guidance and support good communication habits. Students were required to individually submit the full bibliographic reference for their target article to complete step one.


For step two of the assignment, students were required to discuss in their groups to identify 2-3 key claims made by the authors of their target article. They were told to study the data visualizations in the paper to identify which figures seem to give the best support to the authors' claims. Recreating these 1-2 visualisations was a key task for the students in the production of their final report. A second task for step two was for students to identify and obtain the raw data files of their target article. The list of articles that the students chose from only included articles for which data were openly available. This removed the need for students to contact authors to request data, which may have added the risk of a long wait for a favourable reply, refusal to share, or no reply. To complete step two, each student was required to submit a short statement summarising the 2-3 key claims of their target paper, and the raw data file. 


Step three of the assignment required students to create a file structure on their computer to organise their assignment files, to download an R Markdown file and write a small amount of R code to read in the raw data and explore it with one basic visualisation, unrelated to any in the target article. We prepared an R Markdown file with some basic headings (following the IMRaD or  Introduction-Method-Results-and-Discussion format) and empty code chunks to provide guidance on how many code chunks were expected, and where in the document they should appear. As students wrote their R code and encountered errors, they were encouraged to share screenshots on Slack for the instructors to assist with troubleshooting. After completing this step, the instructor met with each group to review the main claims identified by the students, review the visualisation they had chosen to replicate, and provide guidance on writing the R code to produce the key visualisations.  


The final task was for the students to write their report, and submit a reproducible research compendium. This included three files: (1) their R Markdown document, (2)  the raw data file, and (3) the output document (e.g. Microsoft Word document that is produced when they knit the R Markdown file). Our expectation was that we could create any student’s results by running their submitted R Markdown document and the raw data file to produce the Word document they submitted. The final report was graded with a rubric which was presented to the students at the first step to help set expectations about what the final product should look like.


In the time between students submitting their final report and the grades being released we administered an online survey on Canvas to obtain feedback anonymously from the students. The purpose of the feedback survey was to collect information about how to improve the assignment for future classes, to understand the students’ experience of the assignment, and what value they perceive in replication skills for archaeology in general, and for them individually. They had one week to respond survey, which was not a requirement but we encouraged them to give their valuable feedback. The anonymous survey before releasing grade of replication assignment could reduce possible biases from subjective perception when knowing grade to ensure a more reliable feedback. After the online survey was finished, the instructor showed the results to students in a lecture and invited them to share their thoughts for some interesting observations. 


## Results


### Observations on the assignment process


The first step, choosing the target article, revealed the need for some intervention from the instructor to guide students to articles that used relatively simple statistical methods. For example, one group initially chose @Breslawski_Etter_Jorgeson_Boulanger_2018 as their target article, but the key claims in this paper depend on multiple comparisons of multilevel regression models. We explained to the students that if they attempted to replicate a key claim of this paper then they would likely be doing substantially more work than other groups in the class. We invited this group to choose a different target article to ensure a more comparable experience, which they accepted. The statistical backgrounds of our students was highly diverse, so we could not expect students to be very discerning about the statistical complexity of the methods in the articles on the list of potential target articles. As a consequence, we were prepared to intervene to guide their selection of a paper that we could be sure they could successfully replicate, given the time available. 


The second step was mostly straightforward, with students engaging in discussion in class and on Slack to identify the 2-3 key claims of their target paper, and identify the data visualisation that provided the most relevant support to one or more of those claims. Given that not all students have statistical background, the instructor covered some statistical methods they might encounter while reading during lecture, such as principal components analysis, to give them the mathematical concepts behind it. Identifying the data files was less straightforward, with about one third of students failing to correctly identify the data files accompanying their target article. We attribute this to the relatively low level of familiarity of the students in working with raw data, so they are not sure when they are looking at it, and the high degree of variability in how the target article authors make their data open. Some authors include their data as a file in the supplementary information attached to the article, while others deposit their files on an open data repository such as osf.io or figshare.com, and then cite the DOI to the files in their article. Where the data files were nested in several layers of folders, some students struggled to find them. 


The ability to easily share screenshots on Slack was important to the success of the third step. Our intention was that two lab classes earlier in the term that introduced students to some methods for data visualization using R would provide the foundation for succeeding in this step. We have expected that two accompanying lab reports that required to be written with R markdown would help them practice crucial code they might need later. For the lab reports, they used R markdown template we provided to complete tasks of reading data into R, basic data tidying, and data visualization by modifying sample code. However, we found that for some students this was not sufficient practice, and substantial instructor guidance was required to help them complete this step. At the completion of this step, the instructor met one on one with each group to check how successful they were producing a basic visualization using data from the target article, and to discuss the group's strategy to complete the report. This was the most time-consuming aspect of the assignment for the instructor, holding a one hour meeting with each of the five groups. 


## Analysis of the students' anonymous feedback


Thirteen out of sixteen students completed an anonymous feedback survey that includes two single answer questions, five likert scale questions, and two open-ended questions. Single answer questions were designed to know students' prior experiences of replication assignment and using R language. Ratings for likert scale questions were on a 1 through 5 scale starting at "strongly agree" down to "strongly disagree" to understand students opinion and attitude toward replication assignment in archaeology. Two open-ended questions seek to know more about their thoughts for replication in the classroom in general. 


Describe the two figures we have for this… 


## Analysis of the students' grades for the replication assignment


We graded the students’ final submissions using a rubric with criteria that covered content, the introduction, methods, result, and conclusion sections, and style. In Figure \@ref(fig:rubric-scores) we show the distribution and means of student scores for each criterion. The two criteria showing the highest mean score are “Style: use commas and apostrophes correctly, and spell consistently”, and “Intro: has clear statement of the purpose of the report”. All students got a perfect score for these two criteria. High scores for the grammar criterion are expected because these reflect basic writing skills required for many undergraduate-level courses. Students are expected to have learned these in lower level classes before taking this class. The high scores relating to the introduction section may reflect the effectiveness of the scaffolding steps that focussed students on the specific purpose of the assignment . The lowest mean score is for “Content: minimum of 4 scholarly items in the reference list” that shows some people did not include four items. This might result from insufficient prior training in searching for scholarly publications, suggesting that although this is also a skill that should have been acquired before taking this class, many students remain weak at this task. A low mean is also evident for "Intro: has names, locations, and basic chronology of sites", because some students neglected to supply these archaeological details. Future use of this assignment will incorporate these low-scoring criteria into the scaffolding steps to emphasize their importance to students and give an opportunity for early feedback to students. 


The criteria most relevant to the replication component of the assignment, in order from highest mean score to lowest, are "Content: submission includes Rmd file, Data file, and Word file",  "Conclusion: state whether the author’s claims appear to be robust, unreliable, etc","Results: includes 1-2 original plots & description of these", and "Methods: identify the specific results you will replicate". This suggests that we could help students to develop a better skills in narrating their process (writing about methods), and describing and interpreting their data visualizations. In future we may include more fundamental exercises focusing on these tasks in the scaffolding steps. Overall, we find that comparison of the scores for the replication criteria and other criteria shows there is no clear evidence that the replication component of this assignment lowers students’ grades. The two lowest scoring criteria are more generic research and writing skills rather than skills specific to the replication aspect of the assignment. 


Caption: Here is the output from the Canvas grading rubric showing the scores for each student (one dot) and each criterion that we graded the assignment on. The red bar shows the mean score for each criterion. 






## Discussion 


What are the benefits of replication in the classroom?


What are the challenges of replication in the classroom?


What factors could influence the success of replication practice? Term, students’ background, familiarity with programming language, basic techniques and statistics teaching in classes, tutorials, choices of papers for replications


## Conclusion


What are our main findings?


What are the limitations of our study? Small sample size might affect statistical power, feedback survey as an assessment method might be subjective (comparison with grade ), control conditions: other factors that might have impact on the replication paper


What recommendations can we make to other archaeology instructors?
Learning motivation, understanding of statistics and principles behind graphs with some exercises  


What will we do differently in the future?


## Acknowledgements




Table and Figures:




Survey of replication report assignments in other fields
Instructions to students
Grading rubric
R Markdown template snippet 
Feedback survey facet plot




<!-- The following line inserts a page break when the output is MS Word. For page breaks in PDF, use \newpage on its own line.  -->
##### pagebreak


# References 
<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->
<div id="refs"></div>


##### pagebreak


### Colophon


This report was generated on `r Sys.time()` using the following computational environment and dependencies: 


```{r colophon, cache = FALSE}
# which R packages and versions?
devtools::session_info()
```


The current Git commit details are:


```{r}
# what commit is this file at? 
git2r::repository(here::here())
```